\subsection{Statistical Analyses}
Enabling our proposed analyses framework, two key challenges must be addressed. First, capturing (rigid body) motion in 3D. With state-of-the art VR hardware sampling motion data at around 90Hz accessing and recording pose data, position and orientation, is possible\footnote{https://brekel.com/openvr-recorder/}. Further libraries to synchronize data streams across the network exist\footnote{See for example https://github.com/sccn/labstreaminglayer and http://openvibe.inria.fr/, with predominant application across the neurosciences.} providing affordable alternatives to dedicated systems. Second, in order to compare pixel-wise motion data across participants, each participant should exhibit data points at each pixel. Therefore, decreasing spatial resolution by sub-sampling and/or smoothing can be employed to address the second challenge.

The proposed analyses approach can be summarized into three separate steps:
\begin{itemize}
    \item \textbf{Single-subject summary (or first-level).} With this analyses, we were interested in expressing where participants spent most of the time exploring the mazes as a function of experienced presence. Hence, we investigated the location in 2D (X,Y) of the VR headset rigid body, see \ref{imt_task}. To speed up subsequent analyses, we first sub-sampled the motion capture to 1Hz. Then we computed individual averages of these motion capture data (position over time) for each maze. We averaged across the three repeated explorations per maze, as we were not interested in changes over repeated trials but in expressing exploration behavior as a function of experienced presence more generally. With an average exploration duration of ~3 minutes, for each maze and participant ~180 samples were kept in x and y, discarding the third dimension (up-down) in this analyses, \ref{fig:methods} (left) shows one exploration phase of one subject with lines plotted to connect each sample.
    \item \textbf{Enabling group-level inference.} Next, a 2D histogram with fixed edges to maintain equal resolution across participants was computed. In order to increase overlap across participants (second challenge, see above) a 2D (square sized) Gaussian blur was applied to the histogram image. A sigma of 1.5 was chosen for the 2D filter kernel as it resulted in a good overlap across participants while maintaining spatial specificity.
    \item \textbf{Group-level inference (or second-level).} To investigate the impact of experienced presence on each parameter, we calculated a linear regression at each pixel of the map. We specified the model as $pixels \sim\ intercept + presence + error$, hence at each pixel we fit a linear regression across participants with presence scores as the predictor variable. Pixels with data of fewer than 12 participants (critically low N) were kept as `NaN' and not subjected to linear regression analyses. Plotting resulting regression estimates yields a 2D parametric map. Uncorrected p-values were used to plot a contour at significant effects with $p < .05$. The Matlab code used to construct the parametric maps is available online\footnote{https://github.com/lukasgehrke/mobi-3D-tools}. In order to keep the focus of this report on the potential opportunities and due to the exploratory nature of our investigation, we chose not to implement robust statistics and correction for multiple comparisons and direct interested readers elsewhere~\cite{Pernet2011, Wilcox2016a}. Furthermore, accurate correction for multiple comparison correction must consider the shape of the p-values map. In other words, some form of cluster-based statistic taking into account values of neighboring pixels is preferable. Such cluster-based statistics exist, for example cluster-mass and threshold-free cluster enhancement, but are not trivial to report~\cite{Pernet2015}.
\end{itemize}
% \subsubsection{Parametric mapping with movement behavior}