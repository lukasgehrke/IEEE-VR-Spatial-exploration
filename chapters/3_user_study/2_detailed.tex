\subsection{Statistical Analyses}
With the presented approach we aim to promote benefits of greater spatial resolution of movement behavior to assess a variety of phenomena moderating for example the presence experience in VR. Here, a grand average of, e.g. time spent exploring mazes, provides only limited insights due to its spatial dependence. Some participants may spent more time in the corners but walk faster along straights segments while other participants might wander through the mazes with a constant walking speed, not adapting to the features of the environment. Without a two-dimensional resolution, the two different behaviors would average out to the same amount of time spent in a maze. Therefore, we constructed spatial parametric maps. Explained in detail below, we mimicked our approach from established data analyses procedures in cognitive neuroscience and applied it to spatially resolved behavioral data. For the ground work motivating our proposal, as well as a discussion of the state-of-the-art methods linking behavior to brain activity across the cognitive neurosciences consult~\cite{Friston1994b, Bridwell2018a}.

\subsubsection{Parametric mapping with movement behavior}
Enabling our proposed analyses framework, two key challenges must be addressed. First, capturing (rigid body) motion in 3D. With state-of-the art VR hardware sampling motion data at around 90Hz accessing and recording pose data, position and orientation, is possible\footnote{https://brekel.com/openvr-recorder/}. Further libraries to synchronize data streams across the network exist\footnote{See for example https://github.com/sccn/labstreaminglayer and http://openvibe.inria.fr/, with predominant application across the neurosciences.} providing affordable alternatives to dedicated systems. Second, in order to compare motion data pixel-wise across participants, each participant should exhibit data points at each pixel. Therefore, decreasing spatial resolution by sub-sampling and/or smoothing can be employed to address the second challenge.

The proposed analyses approach can be summarized into three separate steps:
\begin{itemize}
    \item \textbf{Single-subject summary (or first-level).} With this analyses, we were interested in expressing where participants spent most of the time exploring the mazes as a function of experienced presence. To speed up subsequent analyses, we first sub-sampled motion capture data of a rigid body calibrated at the VR Headset, see \ref{imt_task}, to 1Hz. Then we computed individual averages of these motion capture data (position over time) for each maze. We averaged across the three repeated explorations per maze, as we were not interested in changes over repeated trials but in expressing exploration behavior as a function of experienced presence more generally. With an average exploration duration of ~3 minutes, for each maze and participant ~180 samples were kept in x and y, discarding the third dimension (up-down) in this analyses, \ref{fig:methods} (left) shows one exploration phase of one subject with lines plotted to connect each sample.
    \item \textbf{Enabling group-level inference.} Next, a 2D histogram with fixed edges to maintain equal resolution across participants was computed. In order to increase overlap across participants (second challenge, see above) a 2D (square sized) Gaussian blur was applied to the histogram image. A sigma of 1.5 was chosen for the 2D filter kernel as it resulted in a good overlap across participants while maintaining spatial specificity.
    \item \textbf{Group-level inference (or second-level).} To investigate the impact of experienced presence on each parameter, we calculated a linear regression at each pixel of the map. We specified the model as $pixels ~ intercept + presence + error$, hence at each pixel we fit a linear regression across participants with presence scores as the predictor variable. Pixels with data of fewer than 12 participants (critically low N) were kept as `NaN' and not subjected to linear regression analyses. Plotting resulting regression estimates yields a 2D parametric map. Uncorrected p-values were used to plot a contour at significant effects with $p < .05$. The Matlab code used to construct the parametric maps is available online\footnote{anonymized}. In order to keep the focus of this report on the potential opportunities and due to the exploratory nature of our investigation, we chose not to implement robust statistics and correction for multiple comparisons and direct interested readers elsewhere~\cite{Pernet2011, Wilcox2016a}. Furthermore, accurate correction for multiple comparison correction must consider the shape of the p-values map. In other words some form of cluster-based statistic, taking into account values of neighboring pixels, is preferable. Such cluster-based statistics exist, for example cluster-mass and threshold-free cluster enhancement, but are not trivial to report~\cite{Pernet2015}.
\end{itemize}
% for anonymization: https://github.com/lukasgehrke/mobi-3D-tools